{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjLeMHLmKNbe",
        "outputId": "e19a6352-3cc5-4dba-fe57-b80569fee763"
      },
      "outputs": [],
      "source": [
        "# install pip dependencies\n",
        "! pip install kagglehub\n",
        "! pip install pandas\n",
        "! pip install torch datasets\n",
        "! pip install ipdb\n",
        "! pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07SmGsskMtoR",
        "outputId": "f05a05b2-9e9b-41b9-fe1e-678523c3708a"
      },
      "outputs": [],
      "source": [
        "# kaggle authentication\n",
        "# upload kaggle.json\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMlU5RnIRD-S"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import tarfile\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akOIb_RFM6as",
        "outputId": "cfd987c1-457f-44d0-890d-0f82a06d1290"
      },
      "outputs": [],
      "source": [
        "# download data to paraquet\n",
        "download_path = kagglehub.dataset_download(\"solarmainframe/ids-intrusion-csv\")\n",
        "raw_csv_files = glob.glob(os.path.join(download_path, \"*.csv\"))\n",
        "print(raw_csv_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUUBuev_gVVW",
        "outputId": "e24deddd-adf9-4ed5-9106-27c3b84ccc1b"
      },
      "outputs": [],
      "source": [
        "# split csvs into managable chunks\n",
        "\n",
        "CSV_FILES = []\n",
        "\n",
        "num_raw_files = len(raw_csv_files)\n",
        "for i, file in enumerate(raw_csv_files):\n",
        "  print(f\"splitting: {i+1}/{num_raw_files}\")\n",
        "  filename = os.path.splitext(os.path.basename(file))[0]\n",
        "  max_bytes = 500 * 1024 * 1024\n",
        "\n",
        "  part_idx = 1\n",
        "  current_size = 0\n",
        "\n",
        "  with open(file, 'r') as infile:\n",
        "    header = infile.readline()\n",
        "    lines_buffer = []\n",
        "    for line in infile:\n",
        "      lines_buffer.append(line)\n",
        "      current_size += len(line.encode('utf-8'))  # size in bytes\n",
        "\n",
        "      # If current chunk exceeds the limit, write to file\n",
        "      if current_size >= max_bytes:\n",
        "        out_path = os.path.join(f\"{filename}_part{part_idx}.csv\")\n",
        "        with open(out_path, 'w') as outfile:\n",
        "          outfile.write(header)\n",
        "          outfile.writelines(lines_buffer)\n",
        "        CSV_FILES.append(out_path)\n",
        "        part_idx += 1\n",
        "        lines_buffer = []\n",
        "        current_size = 0\n",
        "\n",
        "    # Write remaining lines\n",
        "    if lines_buffer:\n",
        "      out_path = os.path.join(f\"{filename}_part{part_idx}.csv\")\n",
        "      with open(out_path, 'w') as outfile:\n",
        "        outfile.write(header)\n",
        "        outfile.writelines(lines_buffer)\n",
        "      CSV_FILES.append(out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CSV_FILES = glob.glob(\"*.csv\")\n",
        "print(CSV_FILES)\n",
        "sorted_csv = sorted(CSV_FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbFsdVa4B-Ho",
        "outputId": "300c1fce-97ab-4348-ae40-b00a7c98f6f4"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(CSV_FILES[1])\n",
        "NUM_COLUMNS = len(test_df.columns)\n",
        "print(test_df.columns)\n",
        "del test_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "runs = {}\n",
        "curr_run = \"\"\n",
        "curr_len = 0\n",
        "\n",
        "for file in sorted_csv:\n",
        "    df = pd.read_csv(file)\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed', errors=\"coerce\")\n",
        "    df = df.sort_values(by='Timestamp')\n",
        "\n",
        "    for l, t in zip(df['Label'], df['Timestamp']):\n",
        "        if pd.isna(t):\n",
        "            continue\n",
        "        if l == curr_run:\n",
        "            curr_len += 1\n",
        "        else:\n",
        "            if curr_run != \"\":\n",
        "                # Update count of this run length for this label\n",
        "                if curr_run not in runs:\n",
        "                    runs[curr_run] = {}\n",
        "\n",
        "                if curr_len not in runs[curr_run]:\n",
        "                    runs[curr_run][curr_len] = 1\n",
        "                else:\n",
        "                    runs[curr_run][curr_len] += 1\n",
        "\n",
        "            # Start new run\n",
        "            curr_len = 1\n",
        "            curr_run = l\n",
        "\n",
        "    # Final run in this file\n",
        "    if curr_run != \"\":\n",
        "        if curr_run not in runs:\n",
        "            runs[curr_run] = {}\n",
        "        if curr_len not in runs[curr_run]:\n",
        "            runs[curr_run][curr_len] = 1\n",
        "        else:\n",
        "            runs[curr_run][curr_len] += 1\n",
        "\n",
        "    curr_len = 0\n",
        "    curr_run = \"\"\n",
        "print(runs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = []\n",
        "for label, lengths in runs.items():\n",
        "    for run_length, count in lengths.items():\n",
        "        data.append({'Label': label, 'Run Length': run_length, 'Frequency': count})\n",
        "\n",
        "df_runs = pd.DataFrame(data)\n",
        "df_runs = df_runs[df_runs['Run Length'] <= 30]\n",
        "\n",
        "pivot_df = df_runs.pivot(index='Run Length', columns='Label', values='Frequency').fillna(0)\n",
        "\n",
        "# Plotting the stacked bar graph\n",
        "pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "\n",
        "plt.title('Frequency of Run Lengths by Label')\n",
        "plt.xlabel('Run Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.ylim(top=600000)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "window_size = 10\n",
        "counts_per_window = []\n",
        "\n",
        "for file in tqdm(sorted_csv):\n",
        "    df = pd.read_csv(file)\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed', errors=\"coerce\")\n",
        "    df = df.sort_values(by='Timestamp')\n",
        "\n",
        "    for i in range(len(df) - window_size + 1):\n",
        "        window = df['Label'].iloc[i:i+window_size]\n",
        "        count = Counter(window)\n",
        "        counts_per_window.append(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_df = pd.DataFrame(counts_per_window).fillna(0).astype(int)\n",
        "counts_df['Malicious'] = counts_df.drop(columns='Benign').sum(axis=1)\n",
        "# counts_df = counts_df[['Benign', 'Malicious']]\n",
        "#print(counts_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_df = counts_df[counts_df['Malicious'] > 0]\n",
        "print(counts_df['Malicious'].value_counts())\n",
        "#counts_df.plot(kind='bar', stacked=True)\n",
        "\n",
        "frequencies = counts_df['Malicious'].value_counts()\n",
        "\n",
        "frequencies.plot(kind='bar')\n",
        "plt.title('Frequency of Appearences in 10 wide frame')\n",
        "plt.xlabel('Appearences')\n",
        "plt.ylabel('Frequency')\n",
        "#plt.ylim(top=600000)\n",
        "plt.xticks(rotation=45)\n",
        "#plt.legend(title='Label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXLhGrO8jMXT",
        "outputId": "68828384-8f79-4a9d-b82e-d6845a40bd0b"
      },
      "outputs": [],
      "source": [
        "# canon columns\n",
        "CANON_COLUMN_INDEX = ['Fwd IAT Tot', 'Fwd Pkt Len Min', 'Down/Up Ratio', 'Dst Port', 'Fwd IAT Std', 'Fwd Header Len', 'Fwd IAT Min', 'Flow IAT Std', 'Active Std', 'Bwd IAT Max', 'Fwd Pkt Len Mean', 'Pkt Size Avg', 'PSH Flag Cnt', 'Flow IAT Mean', 'Fwd Act Data Pkts', 'Bwd Pkt Len Max', 'Flow IAT Max', 'ACK Flag Cnt', 'Bwd IAT Tot', 'Flow IAT Min', 'Bwd Pkts/b Avg', 'Fwd IAT Max', 'SYN Flag Cnt', 'Bwd Header Len', 'Fwd Seg Size Avg', 'Bwd Byts/b Avg', 'Subflow Bwd Byts', 'Pkt Len Max', 'Bwd Pkts/s', 'Fwd IAT Mean', 'Pkt Len Var', 'Fwd Pkt Len Std', 'Protocol', 'Init Bwd Win Byts', 'Active Min', 'Src Port', 'RST Flag Cnt', 'Subflow Fwd Byts', 'Init Fwd Win Byts', 'Bwd Pkt Len Std', 'Fwd PSH Flags', 'Fwd Pkts/s', 'Bwd Blk Rate Avg', 'Flow Byts/s', 'CWE Flag Count', 'Pkt Len Std', 'Active Max', 'Fwd Byts/b Avg', 'Fwd Blk Rate Avg', 'URG Flag Cnt', 'Timestamp', 'Fwd Pkts/b Avg', 'Idle Mean', 'Idle Std', 'Fwd Pkt Len Max', 'Pkt Len Min', 'Flow Duration', 'Fwd Seg Size Min', 'Bwd IAT Min', 'TotLen Fwd Pkts', 'Flow Pkts/s', 'Active Mean', 'ECE Flag Cnt', 'Idle Min', 'Subflow Bwd Pkts', 'Bwd Pkt Len Mean', 'Pkt Len Mean', 'Tot Fwd Pkts', 'Bwd IAT Std', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'Bwd Pkt Len Min', 'Tot Bwd Pkts', 'Subflow Fwd Pkts', 'Bwd IAT Mean', 'FIN Flag Cnt', 'Bwd PSH Flags', 'TotLen Bwd Pkts', 'Fwd URG Flags', 'Idle Max']\n",
        "CANON_COLUMN_INDEX.sort()\n",
        "CANON_COLUMN_INDEX.append('Label')\n",
        "print(CANON_COLUMN_INDEX)\n",
        "TRAINING_UNWANTED_COLUMNS = ['Timestamp', 'Flow ID', 'Dst IP', \"Src IP\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCteS2b1HwyZ",
        "outputId": "e026d55f-d94a-4572-e2b3-8b44bd33a92a"
      },
      "outputs": [],
      "source": [
        "# get normalization stats\n",
        "UNWANTED_COLUMNS_STATS = ['Timestamp','Label', 'Flow ID', 'Dst IP', \"Src IP\"]\n",
        "\n",
        "def calcStatistics(files):\n",
        "  n_total = 0\n",
        "  mean_total = pd.Series(0.0)\n",
        "  M2 = pd.Series(0.0)\n",
        "\n",
        "  file_idx = 0\n",
        "  num_files = len(files)\n",
        "  for file in files:\n",
        "    print(f\"calculating: {file_idx+1}/{num_files}\")\n",
        "    df = pd.read_csv(file)\n",
        "    df = df.reindex(columns=CANON_COLUMN_INDEX)\n",
        "    for col in df.columns:\n",
        "      if col not in UNWANTED_COLUMNS_STATS:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
        "\n",
        "        if col not in mean_total:\n",
        "          mean_total[col] = 0.0\n",
        "          M2[col] = 0.0\n",
        "\n",
        "      else:\n",
        "        df = df.drop(columns=[col])\n",
        "\n",
        "    n = len(df)\n",
        "    mean = df.mean()\n",
        "    var = df.var(ddof=0)\n",
        "\n",
        "    # Welfordâ€™s algorithm for combining means and variances\n",
        "    delta = mean - mean_total\n",
        "    new_n = n_total + n\n",
        "\n",
        "    mean_total = (n_total * mean_total + n * mean) / new_n\n",
        "    M2 += var * n + (delta**2) * n_total * n / new_n\n",
        "\n",
        "    n_total = new_n\n",
        "\n",
        "    file_idx += 1\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "  std = (M2 / n_total) ** 0.5\n",
        "  length = n_total\n",
        "  mean = mean_total\n",
        "  return (length, mean, std)\n",
        "\n",
        "LENGTH, MEAN, STD = calcStatistics(CSV_FILES)\n",
        "\n",
        "import json\n",
        "j = {'length': LENGTH, 'mean': MEAN.to_dict(), 'std': STD.to_dict(), 'non-stat-columns': UNWANTED_COLUMNS_STATS}\n",
        "with open('info.json', 'w') as f:\n",
        "  json.dump(j,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pCO8120Wncm",
        "outputId": "971263d1-582b-4faf-81c0-d153e3f95607"
      },
      "outputs": [],
      "source": [
        "# normalize dataset and convert to parquet\n",
        "! mkdir \"normalized-benign/\"\n",
        "\n",
        "UNWANTED_COLUMNS_NORM = ['Flow ID', 'Dst IP', \"Src IP\"]\n",
        "\n",
        "def normalize(files, mean, std):\n",
        "  pq_files = []\n",
        "\n",
        "  num_files = len(files)\n",
        "  for i,file in enumerate(CSV_FILES):\n",
        "    print(f\"normalizing: {i+1}/{num_files}\")\n",
        "    df = pd.read_csv(file)\n",
        "    df = df.reindex(columns=CANON_COLUMN_INDEX)\n",
        "    filename = os.path.splitext(os.path.basename(file))[0]\n",
        "    name = f'normalized-benign/normalized_{filename}-benign.parquet'\n",
        "    pq_files.append(name)\n",
        "\n",
        "    for col in df.columns:\n",
        "      if col not in UNWANTED_COLUMNS_STATS:\n",
        "          df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
        "          df[col] = (df[col] - mean[col]) / std[col]\n",
        "      else:\n",
        "        if col in UNWANTED_COLUMNS_NORM:\n",
        "          df = df.drop(columns=[col])\n",
        "\n",
        "    if 'Src Port' not in df.columns:\n",
        "      df['Src Port'] = np.nan\n",
        "\n",
        "    df = df[df['Label'] == \"Benign\"]\n",
        "\n",
        "    df.to_parquet(name)\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "  return pq_files\n",
        "\n",
        "PARQUET_FILES = normalize(CSV_FILES, MEAN, STD)\n",
        "print(PARQUET_FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47jYYjNdSD-J"
      },
      "outputs": [],
      "source": [
        "# double check columns\n",
        "base_df = pd.read_parquet(PARQUET_FILES[0])\n",
        "base = set(list(base_df.columns))\n",
        "del base_df\n",
        "gc.collect()\n",
        "\n",
        "for f in PARQUET_FILES:\n",
        "  df = pd.read_parquet(f)\n",
        "\n",
        "  print(df[df['Label'] != \"Benign\"])\n",
        "\n",
        "  cols = set(list(df.columns))\n",
        "  if base != cols:\n",
        "    print(f'in base: {base - cols}, in cols: {cols - base}')\n",
        "  del df\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbCuYDXuobPe",
        "outputId": "30417726-a9bb-4d83-a081-575cacfec4cd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "! tar -czvf normalized-benign-ids2018-parquet.tar.gz normalized-benign/*\n",
        "# ! cp normalized-ids2018.tar.gz drive/MyDrive/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
