{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjLeMHLmKNbe",
        "outputId": "e19a6352-3cc5-4dba-fe57-b80569fee763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests->kagglehub) (2025.7.14)\n",
            "Requirement already satisfied: colorama in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Requirement already satisfied: pandas in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: torch in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (2.7.1+cu128)\n",
            "Requirement already satisfied: datasets in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (0.33.5)\n",
            "Requirement already satisfied: packaging in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: ipdb in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (0.13.13)\n",
            "Requirement already satisfied: ipython>=7.31.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipdb) (9.4.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipdb) (5.2.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (0.4.6)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (2.19.2)\n",
            "Requirement already satisfied: stack_data in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (5.14.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from ipython>=7.31.1->ipdb) (4.14.1)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from stack_data->ipython>=7.31.1->ipdb) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from stack_data->ipython>=7.31.1->ipdb) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from stack_data->ipython>=7.31.1->ipdb) (0.2.3)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from seaborn) (2.3.1)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from seaborn) (2.3.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from seaborn) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\agizi\\ids-hackathon\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.2\n"
          ]
        }
      ],
      "source": [
        "# install pip dependencies\n",
        "! pip install kagglehub\n",
        "! pip install pandas\n",
        "! pip install torch datasets\n",
        "! pip install ipdb\n",
        "! pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07SmGsskMtoR",
        "outputId": "f05a05b2-9e9b-41b9-fe1e-678523c3708a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# kaggle authentication\n",
        "# upload kaggle.json\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iMlU5RnIRD-S"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import tarfile\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akOIb_RFM6as",
        "outputId": "cfd987c1-457f-44d0-890d-0f82a06d1290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-14-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-15-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-16-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-20-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-21-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-22-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-23-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\02-28-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\03-01-2018.csv', 'C:\\\\Users\\\\agizi\\\\.cache\\\\kagglehub\\\\datasets\\\\solarmainframe\\\\ids-intrusion-csv\\\\versions\\\\1\\\\03-02-2018.csv']\n"
          ]
        }
      ],
      "source": [
        "# download data to paraquet\n",
        "download_path = kagglehub.dataset_download(\"solarmainframe/ids-intrusion-csv\")\n",
        "raw_csv_files = glob.glob(os.path.join(download_path, \"*.csv\"))\n",
        "print(raw_csv_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUUBuev_gVVW",
        "outputId": "e24deddd-adf9-4ed5-9106-27c3b84ccc1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "splitting: 1/10\n",
            "splitting: 2/10\n",
            "splitting: 3/10\n",
            "splitting: 4/10\n",
            "splitting: 5/10\n",
            "splitting: 6/10\n",
            "splitting: 7/10\n",
            "splitting: 8/10\n",
            "splitting: 9/10\n",
            "splitting: 10/10\n"
          ]
        }
      ],
      "source": [
        "# split csvs into managable chunks\n",
        "\n",
        "CSV_FILES = []\n",
        "\n",
        "num_raw_files = len(raw_csv_files)\n",
        "for i, file in enumerate(raw_csv_files):\n",
        "  print(f\"splitting: {i+1}/{num_raw_files}\")\n",
        "  filename = os.path.splitext(os.path.basename(file))[0]\n",
        "  max_bytes = 500 * 1024 * 1024\n",
        "\n",
        "  part_idx = 1\n",
        "  current_size = 0\n",
        "\n",
        "  with open(file, 'r') as infile:\n",
        "    header = infile.readline()\n",
        "    lines_buffer = []\n",
        "    for line in infile:\n",
        "      lines_buffer.append(line)\n",
        "      current_size += len(line.encode('utf-8'))  # size in bytes\n",
        "\n",
        "      # If current chunk exceeds the limit, write to file\n",
        "      if current_size >= max_bytes:\n",
        "        out_path = os.path.join(f\"{filename}_part{part_idx}.csv\")\n",
        "        with open(out_path, 'w') as outfile:\n",
        "          outfile.write(header)\n",
        "          outfile.writelines(lines_buffer)\n",
        "        CSV_FILES.append(out_path)\n",
        "        part_idx += 1\n",
        "        lines_buffer = []\n",
        "        current_size = 0\n",
        "\n",
        "    # Write remaining lines\n",
        "    if lines_buffer:\n",
        "      out_path = os.path.join(f\"{filename}_part{part_idx}.csv\")\n",
        "      with open(out_path, 'w') as outfile:\n",
        "        outfile.write(header)\n",
        "        outfile.writelines(lines_buffer)\n",
        "      CSV_FILES.append(out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['02-14-2018_part1.csv', '02-15-2018_part1.csv', '02-16-2018_part1.csv', '02-20-2018_part1.csv', '02-20-2018_part2.csv', '02-20-2018_part3.csv', '02-20-2018_part4.csv', '02-20-2018_part5.csv', '02-20-2018_part6.csv', '02-20-2018_part7.csv', '02-20-2018_part8.csv', '02-21-2018_part1.csv', '02-22-2018_part1.csv', '02-23-2018_part1.csv', '02-28-2018_part1.csv', '03-01-2018_part1.csv', '03-02-2018_part1.csv']\n"
          ]
        }
      ],
      "source": [
        "CSV_FILES = glob.glob(\"*.csv\")\n",
        "print(CSV_FILES)\n",
        "sorted_csv = sorted(CSV_FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbFsdVa4B-Ho",
        "outputId": "300c1fce-97ab-4348-ae40-b00a7c98f6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts',\n",
            "       'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
            "       'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
            "       'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
            "       'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
            "       'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
            "       'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
            "       'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
            "       'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
            "       'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
            "       'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
            "       'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
            "       'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
            "       'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
            "       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
            "       'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
            "       'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
            "       'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
            "       'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
            "       'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
            "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.read_csv(CSV_FILES[1])\n",
        "NUM_COLUMNS = len(test_df.columns)\n",
        "print(test_df.columns)\n",
        "del test_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m curr_len = \u001b[32m0\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m sorted_csv:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m'\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     df = df.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ],
      "source": [
        "\n",
        "runs = {}\n",
        "curr_run = \"\"\n",
        "curr_len = 0\n",
        "\n",
        "for file in sorted_csv:\n",
        "    df = pd.read_csv(file)\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed', errors=\"coerce\")\n",
        "    df = df.sort_values(by='Timestamp')\n",
        "\n",
        "    for l, t in zip(df['Label'], df['Timestamp']):\n",
        "        if pd.isna(t):\n",
        "            continue\n",
        "        if l == curr_run:\n",
        "            curr_len += 1\n",
        "        else:\n",
        "            if curr_run != \"\":\n",
        "                # Update count of this run length for this label\n",
        "                if curr_run not in runs:\n",
        "                    runs[curr_run] = {}\n",
        "\n",
        "                if curr_len not in runs[curr_run]:\n",
        "                    runs[curr_run][curr_len] = 1\n",
        "                else:\n",
        "                    runs[curr_run][curr_len] += 1\n",
        "\n",
        "            # Start new run\n",
        "            curr_len = 1\n",
        "            curr_run = l\n",
        "\n",
        "    # Final run in this file\n",
        "    if curr_run != \"\":\n",
        "        if curr_run not in runs:\n",
        "            runs[curr_run] = {}\n",
        "        if curr_len not in runs[curr_run]:\n",
        "            runs[curr_run][curr_len] = 1\n",
        "        else:\n",
        "            runs[curr_run][curr_len] += 1\n",
        "\n",
        "    curr_len = 0\n",
        "    curr_run = \"\"\n",
        "print(runs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = []\n",
        "for label, lengths in runs.items():\n",
        "    for run_length, count in lengths.items():\n",
        "        data.append({'Label': label, 'Run Length': run_length, 'Frequency': count})\n",
        "\n",
        "df_runs = pd.DataFrame(data)\n",
        "df_runs = df_runs[df_runs['Run Length'] <= 30]\n",
        "\n",
        "pivot_df = df_runs.pivot(index='Run Length', columns='Label', values='Frequency').fillna(0)\n",
        "\n",
        "# Plotting the stacked bar graph\n",
        "pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "\n",
        "plt.title('Frequency of Run Lengths by Label')\n",
        "plt.xlabel('Run Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.ylim(top=600000)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "window_size = 10\n",
        "counts_per_window = []\n",
        "\n",
        "for file in tqdm(sorted_csv):\n",
        "    df = pd.read_csv(file)\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed', errors=\"coerce\")\n",
        "    df = df.sort_values(by='Timestamp')\n",
        "\n",
        "    for i in range(len(df) - window_size + 1):\n",
        "        window = df['Label'].iloc[i:i+window_size]\n",
        "        count = Counter(window)\n",
        "        counts_per_window.append(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_df = pd.DataFrame(counts_per_window).fillna(0).astype(int)\n",
        "counts_df['Malicious'] = counts_df.drop(columns='Benign').sum(axis=1)\n",
        "# counts_df = counts_df[['Benign', 'Malicious']]\n",
        "#print(counts_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_df = counts_df[counts_df['Malicious'] > 0]\n",
        "print(counts_df['Malicious'].value_counts())\n",
        "#counts_df.plot(kind='bar', stacked=True)\n",
        "\n",
        "frequencies = counts_df['Malicious'].value_counts()\n",
        "\n",
        "frequencies.plot(kind='bar')\n",
        "plt.title('Frequency of Appearences in 10 wide frame')\n",
        "plt.xlabel('Appearences')\n",
        "plt.ylabel('Frequency')\n",
        "#plt.ylim(top=600000)\n",
        "plt.xticks(rotation=45)\n",
        "#plt.legend(title='Label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXLhGrO8jMXT",
        "outputId": "68828384-8f79-4a9d-b82e-d6845a40bd0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Src Port', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt', 'Label']\n"
          ]
        }
      ],
      "source": [
        "# canon columns\n",
        "CANON_COLUMN_INDEX = ['Fwd IAT Tot', 'Fwd Pkt Len Min', 'Down/Up Ratio', 'Dst Port', 'Fwd IAT Std', 'Fwd Header Len', 'Fwd IAT Min', 'Flow IAT Std', 'Active Std', 'Bwd IAT Max', 'Fwd Pkt Len Mean', 'Pkt Size Avg', 'PSH Flag Cnt', 'Flow IAT Mean', 'Fwd Act Data Pkts', 'Bwd Pkt Len Max', 'Flow IAT Max', 'ACK Flag Cnt', 'Bwd IAT Tot', 'Flow IAT Min', 'Bwd Pkts/b Avg', 'Fwd IAT Max', 'SYN Flag Cnt', 'Bwd Header Len', 'Fwd Seg Size Avg', 'Bwd Byts/b Avg', 'Subflow Bwd Byts', 'Pkt Len Max', 'Bwd Pkts/s', 'Fwd IAT Mean', 'Pkt Len Var', 'Fwd Pkt Len Std', 'Protocol', 'Init Bwd Win Byts', 'Active Min', 'Src Port', 'RST Flag Cnt', 'Subflow Fwd Byts', 'Init Fwd Win Byts', 'Bwd Pkt Len Std', 'Fwd PSH Flags', 'Fwd Pkts/s', 'Bwd Blk Rate Avg', 'Flow Byts/s', 'CWE Flag Count', 'Pkt Len Std', 'Active Max', 'Fwd Byts/b Avg', 'Fwd Blk Rate Avg', 'URG Flag Cnt', 'Timestamp', 'Fwd Pkts/b Avg', 'Idle Mean', 'Idle Std', 'Fwd Pkt Len Max', 'Pkt Len Min', 'Flow Duration', 'Fwd Seg Size Min', 'Bwd IAT Min', 'TotLen Fwd Pkts', 'Flow Pkts/s', 'Active Mean', 'ECE Flag Cnt', 'Idle Min', 'Subflow Bwd Pkts', 'Bwd Pkt Len Mean', 'Pkt Len Mean', 'Tot Fwd Pkts', 'Bwd IAT Std', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'Bwd Pkt Len Min', 'Tot Bwd Pkts', 'Subflow Fwd Pkts', 'Bwd IAT Mean', 'FIN Flag Cnt', 'Bwd PSH Flags', 'TotLen Bwd Pkts', 'Fwd URG Flags', 'Idle Max']\n",
        "CANON_COLUMN_INDEX.sort()\n",
        "CANON_COLUMN_INDEX.append('Label')\n",
        "print(CANON_COLUMN_INDEX)\n",
        "TRAINING_UNWANTED_COLUMNS = ['Timestamp', 'Flow ID', 'Dst IP', \"Src IP\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCteS2b1HwyZ",
        "outputId": "e026d55f-d94a-4572-e2b3-8b44bd33a92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 1/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 2/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 3/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\agizi\\AppData\\Local\\Temp\\ipykernel_48052\\2849491139.py:13: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 4/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 5/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 6/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 7/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 8/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 9/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 10/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 11/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 12/17\n",
            "calculating: 13/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 14/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 15/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\agizi\\AppData\\Local\\Temp\\ipykernel_48052\\2849491139.py:13: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n",
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 16/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\agizi\\AppData\\Local\\Temp\\ipykernel_48052\\2849491139.py:13: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file)\n",
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating: 17/17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\agizi\\ids-hackathon\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
            "  sqr = _ensure_numeric((avg - values) ** 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16233002 0                            NaN\n",
            "ACK Flag Cnt            0.331602\n",
            "Active Max         262392.688162\n",
            "Active Mean        172878.064598\n",
            "Active Min         115466.010358\n",
            "                       ...      \n",
            "Tot Bwd Pkts            6.312703\n",
            "Tot Fwd Pkts           23.533126\n",
            "TotLen Bwd Pkts      4730.926194\n",
            "TotLen Fwd Pkts       973.036015\n",
            "URG Flag Cnt            0.041713\n",
            "Length: 80, dtype: float64 0                           NaN\n",
            "ACK Flag Cnt       4.707887e-01\n",
            "Active Max         3.319235e+06\n",
            "Active Mean        2.505930e+06\n",
            "Active Min         2.114148e+06\n",
            "                       ...     \n",
            "Tot Bwd Pkts       1.640256e+02\n",
            "Tot Fwd Pkts       1.521134e+03\n",
            "TotLen Bwd Pkts    2.344657e+05\n",
            "TotLen Fwd Pkts    6.216956e+04\n",
            "URG Flag Cnt       1.999327e-01\n",
            "Length: 80, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# get normalization stats\n",
        "UNWANTED_COLUMNS_STATS = ['Timestamp','Label', 'Flow ID', 'Dst IP', \"Src IP\"]\n",
        "\n",
        "def calcStatistics(files):\n",
        "  n_total = 0\n",
        "  mean_total = pd.Series(0.0)\n",
        "  M2 = pd.Series(0.0)\n",
        "\n",
        "  file_idx = 0\n",
        "  num_files = len(files)\n",
        "  for file in files:\n",
        "    print(f\"calculating: {file_idx+1}/{num_files}\")\n",
        "    df = pd.read_csv(file)\n",
        "    df = df.reindex(columns=CANON_COLUMN_INDEX)\n",
        "    for col in df.columns:\n",
        "      if col not in UNWANTED_COLUMNS_STATS:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
        "\n",
        "        if col not in mean_total:\n",
        "          mean_total[col] = 0.0\n",
        "          M2[col] = 0.0\n",
        "\n",
        "      else:\n",
        "        df = df.drop(columns=[col])\n",
        "\n",
        "    n = len(df)\n",
        "    mean = df.mean()\n",
        "    var = df.var(ddof=0)\n",
        "\n",
        "    # Welford’s algorithm for combining means and variances\n",
        "    delta = mean - mean_total\n",
        "    new_n = n_total + n\n",
        "\n",
        "    mean_total = (n_total * mean_total + n * mean) / new_n\n",
        "    M2 += var * n + (delta**2) * n_total * n / new_n\n",
        "\n",
        "    n_total = new_n\n",
        "\n",
        "    file_idx += 1\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "  std = (M2 / n_total) ** 0.5\n",
        "  length = n_total\n",
        "  mean = mean_total\n",
        "  return (length, mean, std)\n",
        "\n",
        "LENGTH, MEAN, STD = calcStatistics(CSV_FILES)\n",
        "print(LENGTH, MEAN, STD)\n",
        "\n",
        "# import json\n",
        "# j = {'length': LENGTH, 'mean': MEAN.to_dict(), 'std': STD.to_dict(), 'non-stat-columns': UNWANTED_COLUMNS_STATS}\n",
        "# with open('info.json', 'w') as f:\n",
        "#   json.dump(j,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pCO8120Wncm",
        "outputId": "971263d1-582b-4faf-81c0-d153e3f95607"
      },
      "outputs": [],
      "source": [
        "# normalize dataset and convert to parquet\n",
        "! mkdir \"normalized-benign/\"\n",
        "\n",
        "UNWANTED_COLUMNS_NORM = ['Flow ID', 'Dst IP', \"Src IP\"]\n",
        "\n",
        "def normalize(files, mean, std):\n",
        "  pq_files = []\n",
        "\n",
        "  num_files = len(files)\n",
        "  for i,file in enumerate(CSV_FILES):\n",
        "    print(f\"normalizing: {i+1}/{num_files}\")\n",
        "    df = pd.read_csv(file)\n",
        "    df = df.reindex(columns=CANON_COLUMN_INDEX)\n",
        "    filename = os.path.splitext(os.path.basename(file))[0]\n",
        "    name = f'normalized-benign/normalized_{filename}-benign.parquet'\n",
        "    pq_files.append(name)\n",
        "\n",
        "    for col in df.columns:\n",
        "      if col not in UNWANTED_COLUMNS_STATS:\n",
        "          df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
        "          df[col] = (df[col] - mean[col]) / std[col]\n",
        "      else:\n",
        "        if col in UNWANTED_COLUMNS_NORM:\n",
        "          df = df.drop(columns=[col])\n",
        "\n",
        "    if 'Src Port' not in df.columns:\n",
        "      df['Src Port'] = np.nan\n",
        "\n",
        "    df = df[df['Label'] == \"Benign\"]\n",
        "\n",
        "    df.to_parquet(name)\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "  return pq_files\n",
        "\n",
        "PARQUET_FILES = normalize(CSV_FILES, MEAN, STD)\n",
        "print(PARQUET_FILES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47jYYjNdSD-J"
      },
      "outputs": [],
      "source": [
        "# double check columns\n",
        "base_df = pd.read_parquet(PARQUET_FILES[0])\n",
        "base = set(list(base_df.columns))\n",
        "del base_df\n",
        "gc.collect()\n",
        "\n",
        "for f in PARQUET_FILES:\n",
        "  df = pd.read_parquet(f)\n",
        "\n",
        "  print(df[df['Label'] != \"Benign\"])\n",
        "\n",
        "  cols = set(list(df.columns))\n",
        "  if base != cols:\n",
        "    print(f'in base: {base - cols}, in cols: {cols - base}')\n",
        "  del df\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbCuYDXuobPe",
        "outputId": "30417726-a9bb-4d83-a081-575cacfec4cd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "! tar -czvf normalized-benign-ids2018-parquet.tar.gz normalized-benign/*\n",
        "# ! cp normalized-ids2018.tar.gz drive/MyDrive/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
